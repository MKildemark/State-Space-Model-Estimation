{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Shock Series Data\n",
    "\n",
    "This notebook analyzes shock series data from an Excel file, tests for normality, and creates histograms with probability density function overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages (uncomment and run only once if you haven't installed these packages)\n",
    "#using Pkg\n",
    "#Pkg.add([\"XLSX\", \"DataFrames\", \"Plots\", \"StatsPlots\", \"Statistics\", \"Distributions\", \"HypothesisTests\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "using XLSX\n",
    "using DataFrames\n",
    "using Plots\n",
    "using StatsPlots\n",
    "using Statistics\n",
    "using Distributions\n",
    "using HypothesisTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Prepare Data\n",
    "\n",
    "Define a function to read the Excel file with specific handling for our requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read Excel data with specific handling requirements:\n",
    "- Skip first empty row\n",
    "- Use second row as column headers\n",
    "- Include columns B to M, but exclude column C\n",
    "- Handle \"#I/T\" values by treating them as missing\n",
    "\"\"\"\n",
    "function read_excel_series(; include_0::Bool=false, file_path=\"data/shockseries.xlsx\")\n",
    "    \n",
    "    # Prep dict\n",
    "    series_dfs = Dict()\n",
    "\n",
    "    # Read the Excel file\n",
    "    xlsx_file = XLSX.readxlsx(file_path)\n",
    "    \n",
    "    for i in 1:2\n",
    "        sheet = xlsx_file[i]  \n",
    "        \n",
    "        # Read the entire data range including headers\n",
    "        data_range = sheet[:]\n",
    "        \n",
    "        # Extract column headers from the second row (row index 2)\n",
    "        headers = data_range[2, :]\n",
    "        \n",
    "        # Create a DataFrame from data, starting from row 3\n",
    "        df_all = DataFrame(data_range[3:end, :], Symbol.(headers))\n",
    "        \n",
    "        # Identify columns to keep (B to M, excluding C in sheet 1)\n",
    "        # Column A contains dates (index 1) C is missing in sheet 1\n",
    "        if i == 1\n",
    "            keep_cols = [2, 4:13...]  # Columns C is missing in sheet 1\n",
    "        else\n",
    "            keep_cols = [2:13...] \n",
    "        end\n",
    "\n",
    "        # Extract only the columns we want\n",
    "        df_filtered = df_all[:, keep_cols]\n",
    "\n",
    "        for col in names(df_filtered)\n",
    "            # Create a new dataframe for this series\n",
    "            series_df = DataFrame()\n",
    "            \n",
    "            # Copy column values with proper handling of problematic values\n",
    "            series_df[!, :value] = map(df_filtered[!, col]) do val\n",
    "                if val isa String && (val == \"#I/T\" || val == \"\" || val == \"NA\")\n",
    "                    return missing\n",
    "                elseif val isa Missing\n",
    "                    return missing\n",
    "                elseif (val == 0 || val == \"0\" || val == \"0.0\") && include_0 == false\n",
    "                    return missing\n",
    "                else\n",
    "                    # Try to convert to Float64, if it fails return missing\n",
    "                    try\n",
    "                        return parse(Float64, string(val))\n",
    "                    catch\n",
    "                        return missing\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            # Remove rows with missing values\n",
    "            series_df = dropmissing(series_df)\n",
    "            \n",
    "            # Store this processed series\n",
    "            series_dfs[string(col)] = series_df\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return series_dfs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = read_excel_series(include_0 = false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shock classifications based on the provided table\n",
    "function add_shock_classifications()\n",
    "    # Create a dictionary mapping series names to their classifications\n",
    "    shock_classifications = Dict(\n",
    "        \"Hamilton\" => \"Oil price\",\n",
    "        \"Kilian\" => \"Oil supply\",\n",
    "        \"CCI\" => \"Oil supply\",  # Caldara, Cavallo, and Iacoviello\n",
    "        \"BHsupply\" => \"Oil supply\",  # Baumeister and Hamilton\n",
    "        \"KilianAERdemand\" => \"Global demand\",\n",
    "        \"KilianAERSupply\" => \"Oil supply\",\n",
    "        \"KilianAERspecific\" => \"Oil-specific demand\",\n",
    "        \"Fernald\" => \"Productivity\",\n",
    "        \"SmetsWoutersProd\" => \"Productivity\",\n",
    "        \"BarskySimsNews\" => \"News\",\n",
    "        \"KurmanOtrokNews\" => \"News\",\n",
    "        \"BeadryPortierNews\" => \"News\",\n",
    "        \"GertlerKaradiFP4\" => \"Monetary policy\", \n",
    "        \"RomerMP\" => \"Monetary policy\",\n",
    "        \"SmetsWoutersMP\" => \"Monetary policy\",\n",
    "        \"Bloom\" => \"Uncertainty\",\n",
    "        \"BakerBloomDavis\" => \"Uncertainty\",\n",
    "        \"Gilchrist\" => \"Financial\",\n",
    "        \"BassetLoan\" => \"Financial\",\n",
    "        \"RomerFiscal\" => \"Fiscal policy\",\n",
    "        \"Ramey\" => \"Fiscal policy\",\n",
    "        \"FischerPeters\" => \"Fiscal policy\",\n",
    "        \"MertensRavnPrivate\" => \"Tax policy\",\n",
    "        \"MertensRavnCorp\" => \"Tax policy\"\n",
    "    )\n",
    "    \n",
    "    return shock_classifications\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Group series by shock category for organized visualization and analysis\n",
    "\"\"\"\n",
    "function group_series_by_category(series_dict)\n",
    "    shock_classifications = add_shock_classifications()\n",
    "    \n",
    "    # Create dictionary to hold series grouped by category\n",
    "    category_groups = Dict()\n",
    "    \n",
    "    # Populate groups\n",
    "    for (series_name, series_data) in series_dict\n",
    "        category = get(shock_classifications, series_name, \"Uncategorized\")\n",
    "        \n",
    "        if !haskey(category_groups, category)\n",
    "            category_groups[category] = Dict()\n",
    "        end\n",
    "        \n",
    "        category_groups[category][series_name] = series_data\n",
    "    end\n",
    "    \n",
    "    return category_groups, shock_classifications\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generate summary statistics organized by shock category\n",
    "\"\"\"\n",
    "function create_category_statistics(series_dict, test_results)\n",
    "    category_groups, shock_classifications = group_series_by_category(series_dict)\n",
    "    \n",
    "    # Create a summary DataFrame with category information\n",
    "    category_summary = DataFrame(\n",
    "        Category = String[],\n",
    "        Series = String[],\n",
    "        Count = Int[],\n",
    "        Min = Float64[],\n",
    "        Max = Float64[],\n",
    "        Mean = Float64[],\n",
    "        Std = Float64[],\n",
    "        Skewness = Float64[],\n",
    "        Kurtosis = Float64[],\n",
    "        Is_Normal = String[]\n",
    "    )\n",
    "    \n",
    "    for (category, group_dict) in category_groups\n",
    "        for (series_name, _) in group_dict\n",
    "            result = test_results[series_name]\n",
    "            is_normal = (pvalue(result.shapiro_wilk) > 0.05 && \n",
    "                         pvalue(result.kolmogorov_smirnov) > 0.05) ? \"Yes\" : \"No\"\n",
    "            \n",
    "            push!(category_summary, (\n",
    "                category,\n",
    "                series_name,\n",
    "                length(series_dict[series_name].value),\n",
    "                minimum(series_dict[series_name].value),\n",
    "                maximum(series_dict[series_name].value),\n",
    "                result.mean,\n",
    "                result.std,\n",
    "                result.skewness,\n",
    "                result.kurtosis,\n",
    "                is_normal\n",
    "            ))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Sort by Category and then by Series\n",
    "    sort!(category_summary, [:Category, :Series])\n",
    "    \n",
    "    return category_summary\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic stats and normality testing\n",
    "\n",
    "Produce basic stats and test each series for normality using Shapiro-Wilk and Kolmogorov-Smirnov tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test if a data series follows a normal distribution\n",
    "\"\"\"\n",
    "function test_normality(series_value, series_name)\n",
    "    data = series_value\n",
    "    #println(\"\\n==== Normality Tests for '$series_name' ====\")\n",
    "    \n",
    "    # Shapiro-Wilk test\n",
    "    sw_test = ShapiroWilkTest(data)\n",
    "    \n",
    "    # Kolmogorov-Smirnov test\n",
    "    Î¼ = mean(data)\n",
    "    Ï = std(data)\n",
    "    ks_test = ExactOneSampleKSTest(data, Normal(Î¼, Ï))\n",
    "    \n",
    "    # Print results\n",
    "    #println(\"Shapiro-Wilk Test:\")\n",
    "    #println(\"W = $(sw_test.W), p-value = $(pvalue(sw_test))\")\n",
    "    #println(\"$(pvalue(sw_test) < 0.05 ? \"Reject\" : \"Fail to reject\") null hypothesis of normality at 5% significance level\")\n",
    "    \n",
    "    #println(\"\\nKolmogorov-Smirnov Test:\")\n",
    "    #println(\"D = $(ks_test.Î´), p-value = $(pvalue(ks_test))\")\n",
    "    #println(\"$(pvalue(ks_test) < 0.05 ? \"Reject\" : \"Fail to reject\") null hypothesis of normality at 5% significance level\")\n",
    "    \n",
    "    # Print skewness and kurtosis\n",
    "    skew = skewness(data)\n",
    "    kurt = kurtosis(data)\n",
    "    #println(\"\\nSkewness: $(round(skew, digits=3)) (0 for normal distribution)\")\n",
    "    #println(\"Excess Kurtosis: $(round(kurt, digits=3)) (0 for normal distribution)\")\n",
    "    \n",
    "    return (shapiro_wilk=sw_test, kolmogorov_smirnov=ks_test, mean = Î¼, std = Ï, skewness=skew, kurtosis=kurt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = Dict()\n",
    "\n",
    "for (key, _) in series_dict\n",
    "    test_results[key] = test_normality(series_dict[\"$key\"].value, key)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Create histograms with normal PDF overlays for each series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create histogram with PDF overlay for a data series\n",
    "\"\"\"\n",
    "function plot_histogram_with_pdf(data; title=\"Distribution Analysis\")\n",
    "\n",
    "    # Create histogram\n",
    "    h = histogram(data, \n",
    "                 normalize=true,\n",
    "                 alpha=0.6,\n",
    "                 label=\"Histogram\", \n",
    "                 title=title,\n",
    "                 xlabel=\"Value\", \n",
    "                 ylabel=\"Density\")\n",
    "    \n",
    "    # Add kernel density estimate\n",
    "    density!(h, data, label=\"KDE\", line=(:black, 2), legend=:topright)\n",
    "    \n",
    "    return h\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each series\n",
    "individual_plots = Dict()\n",
    "\n",
    "for (series_name, _) in series_dict\n",
    "    individual_plots[series_name] = plot_histogram_with_pdf(\n",
    "        series_dict[\"$series_name\"].value, \n",
    "        title=\"Distribution of $series_name\"\n",
    "    )\n",
    "    #display(individual_plots[series_name])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary values to an array first\n",
    "all_plots_array = collect(values(individual_plots))\n",
    "\n",
    "# First combined figure with 12 plots\n",
    "final_plot1 = plot(all_plots_array[1:12]..., \n",
    "                  layout=(4, 3), \n",
    "                  size=(1200, 900), \n",
    "                  margin=5Plots.mm)\n",
    "\n",
    "# Display the first combined plot\n",
    "display(final_plot1)\n",
    "\n",
    "# Save the first combined plot\n",
    "savefig(final_plot1, \"figs/combined_series_distributions_1.png\")\n",
    "\n",
    "# Second combined figure with the remaining 11 plots\n",
    "final_plot2 = plot(all_plots_array[13:23]..., \n",
    "                  layout=(4, 3),  # This will have one empty spot\n",
    "                  size=(1200, 900), \n",
    "                  margin=5Plots.mm)\n",
    "\n",
    "# Display the second combined plot\n",
    "display(final_plot2)\n",
    "\n",
    "# Save the second combined plot\n",
    "savefig(final_plot2, \"figs/combined_series_distributions_2.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Normality Tests\n",
    "\n",
    "Create a summary table with all normality test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table\n",
    "normality_summary = DataFrame(\n",
    "    Series = String[],\n",
    "    SW_Statistic = Float64[],\n",
    "    SW_PValue = Float64[],\n",
    "    KS_Statistic = Float64[],\n",
    "    KS_PValue = Float64[],\n",
    "    Mean = Float64[],\n",
    "    Std = Float64[],\n",
    "    Skewness = Float64[],\n",
    "    Kurtosis = Float64[],\n",
    "    Is_Normal = String[]\n",
    ")\n",
    "\n",
    "for (series_name, series_df) in series_dict\n",
    "    result = test_results[series_name]\n",
    "    is_normal = (pvalue(result.shapiro_wilk) > 0.05 && \n",
    "                 pvalue(result.kolmogorov_smirnov) > 0.05) ? \"Yes\" : \"No\"\n",
    "    \n",
    "    push!(normality_summary, (\n",
    "        series_name,\n",
    "        result.shapiro_wilk.W,\n",
    "        pvalue(result.shapiro_wilk),\n",
    "        result.kolmogorov_smirnov.Î´,\n",
    "        pvalue(result.kolmogorov_smirnov),\n",
    "        result.mean,\n",
    "        result.std,\n",
    "        result.skewness,\n",
    "        result.kurtosis,\n",
    "        is_normal\n",
    "    ))\n",
    "end\n",
    "\n",
    "# Display the summary table\n",
    "normality_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_summary = create_category_statistics(series_dict, test_results)\n",
    "category_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Q plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a Q-Q plot comparing a data series with a normal distribution\n",
    "\"\"\"\n",
    "function plot_qqplot(data, title=\"Q-Q Plot\"; mean_val=nothing, std_val=nothing)\n",
    "    # If mean and std are not provided, calculate them from the data\n",
    "    if isnothing(mean_val) || isnothing(std_val)\n",
    "        mean_val = mean(data)\n",
    "        std_val = std(data)\n",
    "    end\n",
    "    \n",
    "    # Create Q-Q plot against normal distribution\n",
    "    qqplot = qqnorm(data, \n",
    "                   qqline=:fit,  # Add reference line\n",
    "                   title=title,\n",
    "                   xlabel=\"Theoretical Quantiles\",\n",
    "                   ylabel=\"Sample Quantiles\",\n",
    "                   legend=false,\n",
    "                   markersize=3,\n",
    "                   markerstrokewidth=0)\n",
    "    \n",
    "    return qqplot\n",
    "end\n",
    "\n",
    "# Create individual Q-Q plots for each series\n",
    "qq_plots = Dict()\n",
    "\n",
    "for (series_name, _) in series_dict\n",
    "    # Get the mean and std from test_results\n",
    "    mean_val = test_results[\"$series_name\"].mean\n",
    "    std_val = test_results[\"$series_name\"].std\n",
    "    \n",
    "    # Create the Q-Q plot\n",
    "    qq_plots[series_name] = plot_qqplot(\n",
    "        series_dict[\"$series_name\"].value, \n",
    "        \"Q-Q Plot of $series_name\",\n",
    "        mean_val=mean_val,\n",
    "        std_val=std_val\n",
    "    )\n",
    "end\n",
    "\n",
    "# Convert the dictionary values to an array\n",
    "all_qq_plots_array = collect(values(qq_plots))\n",
    "\n",
    "# First combined figure with 12 plots\n",
    "qq_final_plot1 = plot(all_qq_plots_array[1:12]..., \n",
    "                    layout=(4, 3), \n",
    "                    size=(1200, 900), \n",
    "                    margin=5Plots.mm)\n",
    "\n",
    "# Display the first combined plot\n",
    "display(qq_final_plot1)\n",
    "\n",
    "# Save the first combined plot\n",
    "savefig(qq_final_plot1, \"figs/combined_series_qq_plots_1.png\")\n",
    "\n",
    "# Second combined figure with the remaining 11 plots\n",
    "qq_final_plot2 = plot(all_qq_plots_array[13:23]..., \n",
    "                    layout=(4, 3),  # This will have one empty spot\n",
    "                    size=(1200, 900), \n",
    "                    margin=5Plots.mm)\n",
    "\n",
    "# Display the second combined plot\n",
    "display(qq_final_plot2)\n",
    "\n",
    "# Save the second combined plot\n",
    "savefig(qq_final_plot2, \"figs/combined_series_qq_plots_2.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
